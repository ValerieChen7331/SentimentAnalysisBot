import json
from typing import List
from on_premises_llm import OnPremisesLLM
import re

class LLMHelper:
    @staticmethod
    def analyze_article(article: str) -> dict:
        """
        ä¸€æ¬¡æ€§ä¸Ÿçµ¦ LLMï¼Œå–å¾—æ‘˜è¦ã€æƒ…ç·’åˆ†æã€å‘½åå¯¦é«”è¾¨è­˜ (NER)
        :param article: æ–°èå…§æ–‡å­—ä¸²
        :return: dict æ ¼å¼çµæœ
        """
        prompt = (
            "è«‹æ ¹æ“šä»¥ä¸‹æ–°èå…§å®¹ï¼ŒåŒæ™‚ç”¢ç”Ÿï¼š\n"
            "1. æ–°èæ‘˜è¦ï¼ˆ200 å­—å…§ï¼‰\n"
            "2. æƒ…ç·’åˆ¤æ–·ï¼ˆæ­£é¢ã€ä¸­æ€§ã€è² é¢æ“‡ä¸€ï¼‰\n"
            "3. å‘½åå¯¦é«”ï¼ˆåŒ…å«äººåã€å…¬å¸ã€åœ°åï¼Œä»¥é€—è™Ÿåˆ†éš”ï¼‰\n"
            "âš ï¸ æœ€å¾Œè«‹å‹™å¿…ä»¥ä»¥ä¸‹ JSON æ ¼å¼è¼¸å‡ºï¼š\n"
            '{ "summary": "...", "sentiment": "...", "ner": "..." }\n\n'
            "ä»¥ä¸‹ç‚ºæ–°èå…§å®¹ï¼š\n" + article
        )

        llm_instance = OnPremisesLLM()
        response_text = llm_instance.on_premises_llm("Taiwan-Llama3-16f", prompt)
        print("ğŸ§  LLM å›å‚³åŸå§‹çµæœï¼š", response_text)

        # JSON è§£æèˆ‡è‡ªå‹•ä¿®å¾©
        try:
            result = json.loads(response_text)
        except json.JSONDecodeError:
            cleaned_text = response_text.replace("\n", " ").replace("\r", "").strip()
            match = re.search(r'\{.*\}', cleaned_text)
            if match:
                try:
                    result = json.loads(match.group(0))
                except:
                    result = {"summary": "ç„¡æ³•ç”Ÿæˆæ‘˜è¦", "sentiment": "æœªçŸ¥", "ner": "ç„¡"}
            else:
                result = {"summary": "ç„¡æ³•ç”Ÿæˆæ‘˜è¦", "sentiment": "æœªçŸ¥", "ner": "ç„¡"}
        return result

    @staticmethod
    def generate_summary(articles: list, analyses: list) -> str:
        """
        å°‡å¤šç¯‡æ–°èå’Œåˆ†æçµæœç¶œåˆäº¤çµ¦ LLMï¼Œç”¢å‡º 300 å­—ä»¥å…§è¼¿æƒ…æ‘˜è¦
        :param articles: list of dictsï¼ŒåŒ…å« title, publish_date, content
        :param analyses: list of dictsï¼ŒåŒ…å« summary, sentiment, ner
        :return: LLM ç”¢å‡ºæ‘˜è¦
        """
        combined_text = []
        for i, (article, analysis) in enumerate(zip(articles, analyses), start=1):
            block = (
                f"ã€ç¬¬ {i} å‰‡æ–°èã€‘\n"
                f"æ¨™é¡Œï¼š{article['title']}\n"
                f"æ—¥æœŸï¼š{article['publish_date']}\n"
                f"æ‘˜è¦ï¼š{analysis['summary']}\n"
                f"æƒ…ç·’ï¼š{analysis['sentiment']}\n"
                f"NERï¼š{analysis['ner']}\n"
            )
            combined_text.append(block)

        prompt = (
            "ä»¥ä¸‹ç‚ºå¤šç¯‡æ–°èå…§å®¹åŠ AI åˆ†æçµæœï¼Œè«‹ç¶œåˆä»¥ä¸‹å…§å®¹ç”¢å‡º 300 å­—ä»¥å…§çš„è¼¿æƒ…ç¸½çµï¼Œ"
            "ä¸¦èªªæ˜è¼¿è«–è¶¨å‹¢åŠæ½›åœ¨é¢¨éšªï¼š\n\n" + "\n\n".join(combined_text)
        )

        llm_instance = OnPremisesLLM()
        response_text = llm_instance.on_premises_llm("Taiwan-Llama3-16f", prompt)

        if response_text.startswith("æŸ¥è©¢å¤±æ•—"):
            return "âš ï¸ ç„¡æ³•ç”Ÿæˆæ‘˜è¦ï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        return response_text

    @staticmethod
    def query_to_keywords(query: str) -> str:
        """
        å°‡è‡ªç„¶èªè¨€å•é¡Œè½‰æ›ç‚º 1-3 å€‹æœå°‹ç”¨é—œéµå­—
        """
        prompt = f"""
        è«‹æ ¹æ“šä»¥ä¸‹ä½¿ç”¨è€…å•é¡Œï¼Œç”¢ç”Ÿ 1-3 å€‹æœ€é©åˆæ–°èæœå°‹çš„çŸ­é—œéµå­—ï¼ˆé€—è™Ÿåˆ†éš”ï¼‰ï¼Œ
        é—œéµå­—æ‡‰ç°¡æ½”ä¸”ä»£è¡¨ä¸»é¡Œé‡é»ã€‚
        è«‹ä»¥æ­¤æ ¼å¼å›æ‡‰ï¼š
        <qtkeywords> é—œéµå­—1, é—œéµå­—2, é—œéµå­—3 <qtkeywords>

        ä½¿ç”¨è€…è¼¸å…¥: {query}
        """

        llm_instance = OnPremisesLLM()
        response_text = llm_instance.on_premises_llm("Taiwan-Llama3-16f", prompt)
        print(f"ğŸ” LLM é—œéµå­—å›æ‡‰: {response_text}")

        match = re.search(r"<qtkeywords>\s*(.*?)\s*<qtkeywords>", response_text)
        if match:
            keywords_str = match.group(1)
            keywords_list = [kw.strip() for kw in re.split(r"[ï¼Œ,]", keywords_str)]
            return keywords_list[0]  # å›å‚³ç¬¬ä¸€çµ„é—œéµå­—
        else:
            return ""
